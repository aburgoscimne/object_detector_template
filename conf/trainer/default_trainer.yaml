trainer:
  gpus: 1
  distributed_backend: dp
  #accumulate_grad_batches: 1
  profiler: False
  max_epochs: 10
  log_save_interval: 100
  gradient_clip_val: 1
  num_sanity_val_steps: 0
  #weights_summary:
  fast_dev_run: False
  limit_train_batches: 0.05
  limit_val_batches: 0.1
  deterministic: True